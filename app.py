from fastapi import FastAPI, Request
import os
import requests
from dotenv import load_dotenv
from openai import OpenAI
import json

from ai import extrair_os  # usa seu ai.py

load_dotenv()

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_BOT_TOKEN:
    raise RuntimeError("TELEGRAM_BOT_TOKEN nÃ£o encontrado no .env")
if not OPENAI_API_KEY:
    raise RuntimeError("OPENAI_API_KEY nÃ£o encontrado no .env")

openai_client = OpenAI(api_key=OPENAI_API_KEY)

app = FastAPI()


def send_message(chat_id: str, text: str) -> None:
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    requests.post(url, json={"chat_id": chat_id, "text": text}, timeout=30)


def safe_get(d: dict, key: str, default: str = "SEM INFORMAÃ‡ÃƒO") -> str:
    """
    Pega campo do JSON e garante string utilizÃ¡vel.
    Se vier None/vazio, retorna default.
    """
    val = d.get(key, default)
    if val is None:
        return default
    if isinstance(val, str) and val.strip() == "":
        return default
    return str(val)


def format_os_message(data: dict) -> str:
    def safe_get(key: str):
        val = data.get(key)
        if val is None or val == "" or val == "SEM INFORMAÃ‡ÃƒO":
            return "SEM INFORMAÃ‡ÃƒO"
        return str(val)

    equipamento = safe_get("equipamento")
    setor = safe_get("setor")
    solicitante = safe_get("solicitante")
    executor = safe_get("executor")
    descricao = safe_get("descriÃ§Ã£o_do_problema")
    tipo = safe_get("tipo_manutenÃ§Ã£o")
    status = safe_get("status")
    tempo = safe_get("tempo_gasto_minutos")
    custo = safe_get("custo_peÃ§as")
    solucao = safe_get("soluÃ§Ã£o_aplicada")

    msg = (
        "ğŸŸ¢ OS REGISTRADA (PRÃ‰-ANÃLISE)\n\n"
        f"ğŸ”§ Equipamento: {equipamento}\n"
        f"ğŸ“ Setor: {setor}\n"
        f"ğŸ“ Solicitante: {solicitante}\n"
        f"ğŸ‘¨â€ğŸ”§ Executor: {executor}\n"
        f"âš™ï¸ Tipo de manutenÃ§Ã£o: {tipo}\n"
        f"ğŸ“Œ Status: {status}\n"
        f"â± Tempo gasto (min): {tempo}\n"
        f"ğŸ’° Custo de peÃ§as: {custo}\n"
        f"ğŸš¨ Problema detectado:\n{descricao}\n"
        f"ğŸ›  SoluÃ§Ã£o aplicada:\n{solucao}"
    )

    return msg

@app.post("/telegram/webhook")
async def telegram_webhook(request: Request):
    update = await request.json()

    message = update.get("message") or update.get("edited_message")
    if not message:
        return {"ok": True}

    chat_id = str(message["chat"]["id"])

    # Por enquanto: sÃ³ texto (Ã¡udio entra depois)
    if "text" not in message:
        send_message(chat_id, "Por enquanto eu processo apenas texto. Ãudio entra no prÃ³ximo passo.")
        return {"ok": True}

    texto = message["text"]

    try:
        json_str = extrair_os(openai_client, texto)

        # extrair_os retorna uma STRING JSON; aqui convertemos para dict
        data = json.loads(json_str)

        # Garante que veio um objeto
        if not isinstance(data, dict):
            raise ValueError("A IA nÃ£o retornou um objeto JSON vÃ¡lido.")

        # Resposta formatada (estilo Make)
        reply = format_os_message(data)
        send_message(chat_id, reply)

    except Exception as e:
        send_message(chat_id, f"Erro ao interpretar OS: {e}")

    return {"ok": True}


@app.get("/")
def home():
    return {"status": "Servidor rodando"}

@app.get("/health")
def health():
    return {"ok": True}

